{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding scripts to the path of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\KifiyaAIM-Course\\Week - 5\\EthioMart_E-Commerce_NER\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "# Get the parent directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "scripts_path = os.path.join(parent_dir, 'scripts')\n",
    "\n",
    "# Insert the path to the parent directory\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "# Insert the path to the Scripts directory\n",
    "sys.path.insert(0, scripts_path)\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the CoNLL dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.util import read_conll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>lables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ቴሌግራምtmemodernshoppingcenter, በአዲስ, ነገረ, ሁሌም,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-Product, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ቴሌግራምtmemodernshoppingcenter, በአዲስ, ነገረ, ሁሌም,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ቴሌግራምtmemodernshoppingcenter, በአዲስ, ነገረ, ሁሌም,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ቴሌግራምtmemodernshoppingcenter, በአዲስ, ነገረ, ሁሌም,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-Product, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ቴሌግራምtmemodernshoppingcenter, በአዲስ, ነገረ, ሁሌም,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [ቴሌግራምtmemodernshoppingcenter, በአዲስ, ነገረ, ሁሌም,...   \n",
       "1  [ቴሌግራምtmemodernshoppingcenter, በአዲስ, ነገረ, ሁሌም,...   \n",
       "2  [ቴሌግራምtmemodernshoppingcenter, በአዲስ, ነገረ, ሁሌም,...   \n",
       "3  [ቴሌግራምtmemodernshoppingcenter, በአዲስ, ነገረ, ሁሌም,...   \n",
       "4  [ቴሌግራምtmemodernshoppingcenter, በአዲስ, ነገረ, ሁሌም,...   \n",
       "\n",
       "                                              lables  \n",
       "0  [O, O, O, O, O, O, O, O, O, B-Product, O, O, O...  \n",
       "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3  [O, O, O, O, O, O, O, O, O, O, O, B-Product, O...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"../data/conll.txt\"\n",
    "\n",
    "data = read_conll(PATH)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encode the NER labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the unique labels\n",
    "unique_labels = ['I-PRICE', 'B-PRICE', \"B-LOCATION\", \"B-Product\", \"O\"]\n",
    "\n",
    "# now encode them to integers and create mappins between str and int and viceversa\n",
    "enc_to_str = {i: value for i,value in enumerate(unique_labels)}\n",
    "str_to_enc = {value: i for i,value in enumerate(unique_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lables'] = data['lables'].apply(lambda x: [str_to_enc[label] for label in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert the data frame into a huggingface dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\KifiyaAIM-Course\\Week - 5\\EthioMart_E-Commerce_NER\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, Features, Sequence, Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the features/internal structure of the dataset \n",
    "feats = Features({\n",
    "    'tokens': Sequence(Value('string')),\n",
    "    'lables': Sequence(Value('int32'))\n",
    "})\n",
    "\n",
    "# now convert the dataframe into a huggingface dataset  \n",
    "dataset = Dataset.from_pandas(data[['tokens', 'lables']], features=feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tokenize and align the lables for each of the models\n",
    "\n",
    "    The models are **mBert**, **bert-tiny-amharic**, **DistilBert**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, Trainer, AutoModelForTokenClassification, PreTrainedTokenizer\n",
    "from scripts.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the tokenizers using custom class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tiny_tokenizer = Tokenizer(model_name='rasyosef/bert-tiny-amharic')\n",
    "bert_tiny_tokenizer.load_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\KifiyaAIM-Course\\Week - 5\\EthioMart_E-Commerce_NER\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mbert_tokenizer = Tokenizer(model_name='bert-base-multilingual-cased')\n",
    "mbert_tokenizer.load_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "distil_bert_tokenizer = Tokenizer(model_name='distilbert-base-multilingual-cased')\n",
    "distil_bert_tokenizer.load_tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2161/2161 [00:00<00:00, 2375.11 examples/s]\n",
      "Map: 100%|██████████| 2161/2161 [00:00<00:00, 2687.87 examples/s]\n",
      "Map: 100%|██████████| 2161/2161 [00:00<00:00, 2907.23 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_bert_tiny = dataset.map(bert_tiny_tokenizer.tokenize_and_align, batched=True)\n",
    "tokenized_mbert = dataset.map(mbert_tokenizer.tokenize_and_align, batched=True)\n",
    "tokenized_distil_bert = dataset.map(distil_bert_tokenizer.tokenize_and_align, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the datasets into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_bert_tiny = tokenized_bert_tiny.train_test_split(test_size=0.1)\n",
    "train_test_mbert = tokenized_mbert.train_test_split(test_size=0.1)\n",
    "train_test_distill_bert = tokenized_distil_bert.train_test_split(test_size=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
